{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d674b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.schema import MetadataMode\n",
    "import openai\n",
    "from openai import OpenAI as OpenAIOG\n",
    "import logging\n",
    "import sys\n",
    "llm = OpenAI(temperature=0.0, model=\"gpt-3.5-turbo\")\n",
    "client = OpenAIOG()\n",
    "\n",
    "from langdetect import detect\n",
    "from langdetect import DetectorFactory\n",
    "DetectorFactory.seed = 0\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "# Load index\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core import load_index_from_storage\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"arv_metadata\")\n",
    "index = load_index_from_storage(storage_context)\n",
    "query_engine = index.as_query_engine(similarity_top_k=3, llm=llm)\n",
    "\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65e50ad",
   "metadata": {},
   "source": [
    "Current app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4afe48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 4.19.2, however version 4.29.0 is available, please upgrade.\n",
      "--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying llama_index.embeddings.openai.base.get_embedding in 0.5778727161644901 seconds as it raised APIConnectionError: Connection error..\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\httpx\\_transports\\default.py\", line 66, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\httpx\\_transports\\default.py\", line 228, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\httpcore\\_sync\\connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\httpcore\\_sync\\connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\httpcore\\_sync\\connection.py\", line 154, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\httpcore\\_backends\\sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"C:\\Users\\jonathan.friedman\\AppData\\Local\\anaconda3\\lib\\contextlib.py\", line 153, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\httpcore\\_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\openai\\_base_client.py\", line 918, in _request\n",
      "    response = self._client.send(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\httpx\\_client.py\", line 901, in send\n",
      "    response = self._send_handling_auth(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\httpx\\_client.py\", line 929, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\httpx\\_client.py\", line 966, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\httpx\\_client.py\", line 1002, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\httpx\\_transports\\default.py\", line 227, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"C:\\Users\\jonathan.friedman\\AppData\\Local\\anaconda3\\lib\\contextlib.py\", line 153, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\httpx\\_transports\\default.py\", line 83, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\gradio\\queueing.py\", line 495, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\gradio\\route_utils.py\", line 235, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\gradio\\blocks.py\", line 1627, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\gradio\\blocks.py\", line 1173, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2144, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\gradio\\utils.py\", line 690, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\jonathan.friedman\\AppData\\Local\\Temp\\ipykernel_21404\\1203717406.py\", line 10, in nishauri\n",
      "    response = query_engine.query(question)\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\llama_index\\core\\base\\base_query_engine.py\", line 40, in query\n",
      "    return self._query(str_or_query_bundle)\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\llama_index\\core\\query_engine\\retriever_query_engine.py\", line 186, in _query\n",
      "    nodes = self.retrieve(query_bundle)\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\llama_index\\core\\query_engine\\retriever_query_engine.py\", line 142, in retrieve\n",
      "    nodes = self._retriever.retrieve(query_bundle)\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\llama_index\\core\\base\\base_retriever.py\", line 229, in retrieve\n",
      "    nodes = self._retrieve(query_bundle)\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\llama_index\\core\\indices\\vector_store\\retrievers\\retriever.py\", line 90, in _retrieve\n",
      "    self._embed_model.get_agg_embedding_from_queries(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\llama_index\\core\\base\\embeddings\\base.py\", line 141, in get_agg_embedding_from_queries\n",
      "    query_embeddings = [self.get_query_embedding(query) for query in queries]\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\llama_index\\core\\base\\embeddings\\base.py\", line 141, in <listcomp>\n",
      "    query_embeddings = [self.get_query_embedding(query) for query in queries]\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\llama_index\\core\\base\\embeddings\\base.py\", line 110, in get_query_embedding\n",
      "    query_embedding = self._get_query_embedding(query)\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\llama_index\\embeddings\\openai\\base.py\", line 374, in _get_query_embedding\n",
      "    return get_embedding(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\tenacity\\__init__.py\", line 289, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\tenacity\\__init__.py\", line 379, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\tenacity\\__init__.py\", line 325, in iter\n",
      "    raise retry_exc.reraise()\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\tenacity\\__init__.py\", line 158, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "  File \"C:\\Users\\jonathan.friedman\\AppData\\Local\\anaconda3\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\jonathan.friedman\\AppData\\Local\\anaconda3\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\tenacity\\__init__.py\", line 382, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\llama_index\\embeddings\\openai\\base.py\", line 137, in get_embedding\n",
      "    client.embeddings.create(input=[text], model=engine, **kwargs).data[0].embedding\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\openai\\resources\\embeddings.py\", line 113, in create\n",
      "    return self._post(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\openai\\_base_client.py\", line 1200, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\openai\\_base_client.py\", line 889, in request\n",
      "    return self._request(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\openai\\_base_client.py\", line 942, in _request\n",
      "    return self._retry_request(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\openai\\_base_client.py\", line 1013, in _retry_request\n",
      "    return self._request(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\openai\\_base_client.py\", line 942, in _request\n",
      "    return self._retry_request(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\openai\\_base_client.py\", line 1013, in _retry_request\n",
      "    return self._request(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\openai\\_base_client.py\", line 942, in _request\n",
      "    return self._retry_request(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\openai\\_base_client.py\", line 1013, in _retry_request\n",
      "    return self._request(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\openai\\_base_client.py\", line 942, in _request\n",
      "    return self._retry_request(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\openai\\_base_client.py\", line 1013, in _retry_request\n",
      "    return self._request(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\openai\\_base_client.py\", line 942, in _request\n",
      "    return self._retry_request(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\openai\\_base_client.py\", line 1013, in _retry_request\n",
      "    return self._request(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\openai\\_base_client.py\", line 942, in _request\n",
      "    return self._retry_request(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\openai\\_base_client.py\", line 1013, in _retry_request\n",
      "    return self._request(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\openai\\_base_client.py\", line 942, in _request\n",
      "    return self._retry_request(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\openai\\_base_client.py\", line 1013, in _retry_request\n",
      "    return self._request(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\openai\\_base_client.py\", line 942, in _request\n",
      "    return self._retry_request(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\openai\\_base_client.py\", line 1013, in _retry_request\n",
      "    return self._request(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\openai\\_base_client.py\", line 942, in _request\n",
      "    return self._retry_request(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\openai\\_base_client.py\", line 1013, in _retry_request\n",
      "    return self._request(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\openai\\_base_client.py\", line 942, in _request\n",
      "    return self._retry_request(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\openai\\_base_client.py\", line 1013, in _retry_request\n",
      "    return self._request(\n",
      "  File \"C:\\Users\\jonathan.friedman\\OneDrive - Palladium International, LLC\\Documents\\Data.FI\\HOP_CLM\\llama10\\lib\\site-packages\\openai\\_base_client.py\", line 952, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n"
     ]
    }
   ],
   "source": [
    "def nishauri(question: str, conversation_history: list[str]):\n",
    "    \n",
    "    context = \" \".join([item[\"user\"] + \" \" + item[\"chatbot\"] for item in conversation_history])\n",
    "\n",
    "    lang_question = detect(question)\n",
    "    \n",
    "    if lang_question==\"sw\":\n",
    "        question = GoogleTranslator(source='sw', target='en').translate(question)\n",
    "        \n",
    "    response = query_engine.query(question)\n",
    "\n",
    "    background = (\"The person who asked the question is a person living with HIV.\"\n",
    "                  \" If the person says sasa or niaje, that is swahili slang for hello.\"\n",
    "            \" Recognize that they already have HIV and do not suggest that they have to get tested\"\n",
    "            \" for HIV or take post-exposure prophylaxis, as that is not relevant, though their partners perhaps should.\"  \n",
    "            \" Do not suggest anything that is not relevant to someone who already has HIV.\"\n",
    "             \" Do not mention in the response that the person is living with HIV.\"\n",
    "            \" The following information about viral loads is authoritative for any question about viral loads:\"\n",
    "           \" Under 50 copies/ml is low detectable level,\"\n",
    "           \" 50 - 199 copies/ml is low level viremia, 200 - 999 is high level viremia, and \"\n",
    "           \" 1000 and above is suspected treatment failure.\" \n",
    "           \" A high viral load or non-suppressed viral load is any viral load above 200 copies/ml.\"\n",
    "           \" A suppressed viral load is one below 200 copies / ml.\")\n",
    "\n",
    "    question_final = (\n",
    "        f\"The user previously asked and answered the following: {context}\"\n",
    "        f\" The user just asked the following question: {question}\"\n",
    "        f\" The following response was generated in response: {response}\"\n",
    "        f\" Please update the response provided only if needed, based on the following background information {background}\"\n",
    "    )\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "        {\"role\": \"user\", \"content\": question_final}\n",
    "      ]\n",
    "    )\n",
    "\n",
    "    reply_to_user = completion.choices[0].message.content\n",
    "    \n",
    "    if lang_question==\"sw\":\n",
    "        reply_to_user = GoogleTranslator(source='auto', target='sw').translate(reply_to_user)\n",
    "    \n",
    "    conversation_history.append({\"user\": question, \"chatbot\": response.response})   \n",
    "\n",
    "    return reply_to_user, conversation_history\n",
    "\n",
    "demo = gr.Interface(\n",
    "    title = \"Nishauri Chatbot Demo\",\n",
    "    fn=nishauri,\n",
    "    inputs=[\"text\", gr.State(value=[])],\n",
    "    outputs=[\"text\", gr.State()],\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaace17",
   "metadata": {},
   "source": [
    "Set up DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6094d8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "    MetaData,\n",
    "    Table,\n",
    "    Column,\n",
    "    String,\n",
    "    Integer,\n",
    "    Date,\n",
    "    select,\n",
    "    column,\n",
    "    insert,\n",
    "    text\n",
    ")\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8817c420",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_file = 'patient_information.csv'\n",
    "df = pd.read_csv(patient_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cc6ae83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ccc_no', 'visit_date', 'visit_type', 'regimen', 'viral_load'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['patient_id', 'gender', 'date_of_birth'], axis = 1)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5567b6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ccc_no</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visit_type</th>\n",
       "      <th>regimen</th>\n",
       "      <th>viral_load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1234567891</td>\n",
       "      <td>2024-03-28</td>\n",
       "      <td>FOLLOWUP</td>\n",
       "      <td>TDF+3TC+NVP</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1287602614</td>\n",
       "      <td>2024-05-06</td>\n",
       "      <td>FOLLOWUP</td>\n",
       "      <td>TDF/3TC/DTG</td>\n",
       "      <td>&lt; LDL copies/ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1287601459</td>\n",
       "      <td>2024-04-16</td>\n",
       "      <td>PHARMACY_REFILL</td>\n",
       "      <td>TDF/3TC/DTG</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1287602420</td>\n",
       "      <td>2024-03-12</td>\n",
       "      <td>PHARMACY_REFILL</td>\n",
       "      <td>TDF/3TC/DTG</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1287604453</td>\n",
       "      <td>2024-04-18</td>\n",
       "      <td>FOLLOWUP</td>\n",
       "      <td>TDF/3TC/DTG</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>15815000197</td>\n",
       "      <td>2023-10-18</td>\n",
       "      <td>CLINICAL</td>\n",
       "      <td>CF2G</td>\n",
       "      <td>100 cp/mL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1613800567</td>\n",
       "      <td>2023-10-11</td>\n",
       "      <td>CLINICAL</td>\n",
       "      <td>AF2E</td>\n",
       "      <td>100 cp/mL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1582807378</td>\n",
       "      <td>2023-10-17</td>\n",
       "      <td>CLINICAL</td>\n",
       "      <td>AF2E</td>\n",
       "      <td>100 cp/mL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1607500140</td>\n",
       "      <td>2023-09-05</td>\n",
       "      <td>CLINICAL</td>\n",
       "      <td>CF5X</td>\n",
       "      <td>100 cp/mL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1613800571</td>\n",
       "      <td>2023-08-03</td>\n",
       "      <td>CLINICAL</td>\n",
       "      <td>AF2E</td>\n",
       "      <td>100 cp/mL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ccc_no visit_date       visit_type      regimen       viral_load\n",
       "0      1234567891 2024-03-28         FOLLOWUP  TDF+3TC+NVP              150\n",
       "1      1287602614 2024-05-06         FOLLOWUP  TDF/3TC/DTG  < LDL copies/ml\n",
       "2      1287601459 2024-04-16  PHARMACY_REFILL  TDF/3TC/DTG              150\n",
       "3      1287602420 2024-03-12  PHARMACY_REFILL  TDF/3TC/DTG              150\n",
       "4      1287604453 2024-04-18         FOLLOWUP  TDF/3TC/DTG              150\n",
       "...           ...        ...              ...          ...              ...\n",
       "1995  15815000197 2023-10-18         CLINICAL         CF2G        100 cp/mL\n",
       "1996   1613800567 2023-10-11         CLINICAL         AF2E        100 cp/mL\n",
       "1997   1582807378 2023-10-17         CLINICAL         AF2E        100 cp/mL\n",
       "1998   1607500140 2023-09-05         CLINICAL         CF5X        100 cp/mL\n",
       "1999   1613800571 2023-08-03         CLINICAL         AF2E        100 cp/mL\n",
       "\n",
       "[2000 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['visit_date'] = pd.to_datetime(df['visit_date'], format='%d/%m/%Y')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cc6e63f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccc_user = \"1287600796\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dedd22f",
   "metadata": {},
   "source": [
    "Let's create the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "142336f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///nishauri.db')\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(\n",
    "        text(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS nishauri (\n",
    "            ccc_no TEXT,\n",
    "            visit_date DATE,\n",
    "            visit_type TEXT,\n",
    "            regimen TEXT,\n",
    "            viral_load TEXT\n",
    "        )\n",
    "        \"\"\")\n",
    "    )\n",
    "\n",
    "# Step 3: Insert data from the CSV into the database\n",
    "df.to_sql('nishauri', con=engine, index=False, if_exists='append')\n",
    "\n",
    "# Step 4: Close the connection\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68e4227",
   "metadata": {},
   "source": [
    "Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "68d27d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7875\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7875/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 4.19.2, however version 4.29.0 is available, please upgrade.\n",
      "--------\n",
      "sw\n",
      "I'm here to help. What specific question or topic would you like assistance with?\n"
     ]
    }
   ],
   "source": [
    "def nishauri(question: str, conversation_history: list[str]):\n",
    "    \n",
    "    context = \" \".join([item[\"user\"] + \" \" + item[\"chatbot\"] for item in conversation_history])\n",
    "\n",
    "    # Get patient info from DB\n",
    "    engine = create_engine('sqlite:///nishauri.db')\n",
    "    \n",
    "    with engine.connect() as connection:\n",
    "        # Select data using a parameterized query\n",
    "        result = connection.execute(\n",
    "            text(\"SELECT visit_date, visit_type, regimen, viral_load FROM nishauri WHERE ccc_no = :ccc_no\"),\n",
    "            {\"ccc_no\": ccc_user}\n",
    "        )\n",
    "    \n",
    "    # Fetch and print results\n",
    "    row = result.fetchall()\n",
    "\n",
    "    last_appt = row[0][0]\n",
    "    appt_purpose = row[0][1]\n",
    "    regimen = row[0][2]\n",
    "    vl_result = row[0][3]\n",
    "    \n",
    "    \n",
    "    # Detect language of question - if Swahili, translate to English\n",
    "    # only do this if there are at least 5 words in the text, otherwise lang detection is unreliable\n",
    "    \n",
    "    # Split the string into words\n",
    "    words = question.split()\n",
    "\n",
    "    # Count the number of words\n",
    "    num_words = len(words)\n",
    "\n",
    "    lang_question = \"en\"\n",
    "    \n",
    "    if num_words > 4:\n",
    "        lang_question = detect(question)\n",
    "    \n",
    "#     lang_question = detect(question)\n",
    "\n",
    "    if lang_question==\"sw\":\n",
    "        question = GoogleTranslator(source='sw', target='en').translate(question)\n",
    "    \n",
    "    context_initial = (\"Here is context for the user's question:\"\n",
    "                       f\" The person's last appointment was on {last_appt} and the purpose was {appt_purpose}. \"\n",
    "                       f\" The person is on the following regimen for HIV {regimen}. \"\n",
    "                       f\" The person's most recent viral load result was {vl_result}. \"\n",
    "                       \"Here is the user's question: \")\n",
    "                    \n",
    "    \n",
    "    response = query_engine.query(question)\n",
    "\n",
    "    print(response)\n",
    "    \n",
    "    # https://docs.llamaindex.ai/en/stable/examples/prompts/prompts_rag/\n",
    "    # based on \"refine\" template\n",
    "    \n",
    "    # Refine the answer if needed\n",
    "    \n",
    "    background = (\"The person who asked the question is a person living with HIV.\"\n",
    "                  \" If the person says sasa or niaje, that is swahili slang for hello.\"\n",
    "            \" Recognize that they already have HIV and do not suggest that they have to get tested\"\n",
    "            \" for HIV or take post-exposure prophylaxis, as that is not relevant, though their partners perhaps should.\"  \n",
    "            \" Do not suggest anything that is not relevant to someone who already has HIV.\"\n",
    "            \" Do not mention in the response that the person is living with HIV.\"\n",
    "#             f\" The person's last appointment was on {last_appt} and the purpose was {appt_purpose}. \"\n",
    "#             f\" The person is on the following regimen for HIV {regimen}. \"\n",
    "#             f\" The person's most recent viral load result was {vl_result}. \"\n",
    "            \" The following information about viral loads is authoritative for any question about viral loads:\"\n",
    "           \" Under 50 copies/ml is low detectable level,\"\n",
    "           \" 50 - 199 copies/ml is low level viremia, 200 - 999 is high level viremia, and \"\n",
    "           \" 1000 and above is suspected treatment failure.\" \n",
    "           \" A high viral load or non-suppressed viral load is any viral load above 200 copies/ml.\"\n",
    "           \" A suppressed viral load is one below 200 copies / ml.\")\n",
    "\n",
    "    question_final = (\n",
    "        f\" The user previously asked and answered the following: {context}. \"\n",
    "        f\" The user just asked the following question: {question}.\"\n",
    "        f\" The following response was generated in response: {response}.\"\n",
    "        f\" Please update the response provided only if needed, based on the following context: {background}\"\n",
    "    )\n",
    "\n",
    "#     print(question_final)\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "        {\"role\": \"user\", \"content\": question_final}\n",
    "      ]\n",
    "    )\n",
    "\n",
    "    reply_to_user = completion.choices[0].message.content\n",
    "    \n",
    "    \n",
    "    # If initial question was in Swahili, translate response back to Swahili\n",
    "    if lang_question==\"sw\":\n",
    "        reply_to_user = GoogleTranslator(source='auto', target='sw').translate(reply_to_user)\n",
    "    \n",
    "    conversation_history.append({\"user\": question, \"chatbot\": reply_to_user})   \n",
    "\n",
    "    return reply_to_user, conversation_history\n",
    "\n",
    "demo = gr.Interface(\n",
    "    title = \"Nishauri Chatbot Demo\",\n",
    "    fn=nishauri,\n",
    "    inputs=[\"text\", gr.State(value=[])],\n",
    "    outputs=[\"text\", gr.State()],\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44a81f7",
   "metadata": {},
   "source": [
    "Retrieval + Synthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8a11614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = index.as_retriever(k = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "24d01d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7893\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7893/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 4.19.2, however version 4.29.0 is available, please upgrade.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "def nishauri(question: str, ccc_user: str, conversation_history: list[str]):\n",
    "    \n",
    "    context = \" \".join([item[\"user\"] + \" \" + item[\"chatbot\"] for item in conversation_history])\n",
    "\n",
    "    # Get patient info from DB\n",
    "    engine = create_engine('sqlite:///nishauri.db')\n",
    "    \n",
    "    with engine.connect() as connection:\n",
    "        # Select data using a parameterized query\n",
    "        result = connection.execute(\n",
    "            text(\"SELECT visit_date, visit_type, regimen, viral_load FROM nishauri WHERE ccc_no = :ccc_no\"),\n",
    "            {\"ccc_no\": ccc_user}\n",
    "        )\n",
    "    \n",
    "    # Fetch and print results\n",
    "    row = result.fetchall()\n",
    "\n",
    "    last_appt = row[0][0]\n",
    "    appt_purpose = row[0][1]\n",
    "    regimen = row[0][2]\n",
    "    vl_result = row[0][3]\n",
    "    \n",
    "    \n",
    "    # Detect language of question - if Swahili, translate to English\n",
    "    # only do this if there are at least 5 words in the text, otherwise lang detection is unreliable\n",
    "    \n",
    "    # Split the string into words\n",
    "    words = question.split()\n",
    "\n",
    "    # Count the number of words\n",
    "    num_words = len(words)\n",
    "\n",
    "    lang_question = \"en\"\n",
    "    \n",
    "    if num_words > 4:\n",
    "        lang_question = detect(question)\n",
    "    \n",
    "#     lang_question = detect(question)\n",
    "\n",
    "    if lang_question==\"sw\":\n",
    "        question = GoogleTranslator(source='sw', target='en').translate(question)                   \n",
    "    \n",
    "    sources = retriever.retrieve(question)\n",
    "    source0 = sources[0].text\n",
    "    source1 = sources[1].text\n",
    "    \n",
    "    background = (\"The person who asked the question is a person living with HIV.\"\n",
    "                  \" If the person says sasa or niaje, that is swahili slang for hello. Just say hello back and ask how you can help.\"\n",
    "                  \" Recognize that they already have HIV and do not suggest that they have to get tested\"\n",
    "                  \" for HIV or take post-exposure prophylaxis, as that is not relevant, though their partners perhaps should.\"  \n",
    "                  \" Do not suggest anything that is not relevant to someone who already has HIV.\"\n",
    "                  \" Do not mention in the response that the person is living with HIV.\"\n",
    "                  f\" The person's next appointment is on {last_appt} and the purpose is {appt_purpose}. \"\n",
    "                  f\" The person is on the following regimen for HIV: {regimen}. \"\n",
    "                  f\" The person's most recent viral load result was {vl_result}. \"\n",
    "                  \" The following information about viral loads is authoritative for any question about viral loads:\"\n",
    "                  \" Under 50 copies/ml is low detectable level,\"\n",
    "                  \" 50 - 199 copies/ml is low level viremia, 200 - 999 is high level viremia, and \"\n",
    "                  \" 1000 and above is suspected treatment failure.\" \n",
    "                  \" A high viral load or non-suppressed viral load is any viral load above 200 copies/ml.\"\n",
    "                  \" A suppressed viral load is one below 200 copies / ml.\"\n",
    "                  \" For questions about when patients should get their viral loads taken,\" \n",
    "                  \" if they are newly initiated on ART, the first viral load sample should be taken after 3 months of\"\n",
    "                  \" taking ART. Otherwise, if they are not new on ART, then if their previous result was below 50 to 199 cp/ml,\"\n",
    "                  \" their viral load should be taken after every 12 months. If  their previous result was above 200cp/ml,\"\n",
    "                  \" then viral load sample should be taken after three months.\")\n",
    "\n",
    "    question_final = (\n",
    "        f\" The user previously asked and answered the following: {context}. \"\n",
    "        f\" The user just asked the following question: {question}.\"\n",
    "        f\" Please use the following content to generate a response: {source0} {source1}.\"\n",
    "        f\" The following background on the user should also inform the response as needed: {background}\"\n",
    "        \" Keep answers brief and limited to the question that was asked.\"\n",
    "        \" Do not provide information the user did not ask about. If they start with a greeting, just greet them in return and don't share anything else.\"\n",
    "    )\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "      model=\"gpt-4-turbo\",\n",
    "        messages=[\n",
    "        {\"role\": \"user\", \"content\": question_final}\n",
    "      ]\n",
    "    )\n",
    "\n",
    "    reply_to_user = completion.choices[0].message.content\n",
    "    \n",
    "    \n",
    "    # If initial question was in Swahili, translate response back to Swahili\n",
    "    if lang_question==\"sw\":\n",
    "        reply_to_user = GoogleTranslator(source='auto', target='sw').translate(reply_to_user)\n",
    "    \n",
    "    conversation_history.append({\"user\": question, \"chatbot\": reply_to_user})   \n",
    "\n",
    "    return reply_to_user, conversation_history\n",
    "\n",
    "\n",
    "demo = gr.Interface(\n",
    "    title = \"Nishauri Chatbot Demo\",\n",
    "    fn=nishauri,\n",
    "    inputs=[gr.Textbox(label=\"question\", placeholder=\"Type your question here...\"),\n",
    "            gr.Textbox(label=\"CCC\", placeholder=\"Type your ccc here...\"),\n",
    "            gr.State(value = [])],\n",
    "    outputs=[\"text\", gr.State()],\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e6245d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                                  VersionNote: you may need to restart the kernel to use updated packages.\n",
      "---------------------------------------- -----------\n",
      "accelerate                               0.27.2\n",
      "aiofiles                                 23.2.1\n",
      "aiohttp                                  3.9.3\n",
      "aiosignal                                1.3.1\n",
      "alembic                                  1.13.1\n",
      "altair                                   5.2.0\n",
      "annotated-types                          0.6.0\n",
      "anyio                                    4.3.0\n",
      "asgiref                                  3.7.2\n",
      "asttokens                                2.4.1\n",
      "async-timeout                            4.0.3\n",
      "attrs                                    23.2.0\n",
      "backoff                                  2.2.1\n",
      "bcrypt                                   4.1.2\n",
      "beautifulsoup4                           4.12.3\n",
      "blinker                                  1.7.0\n",
      "Bottleneck                               1.3.8\n",
      "bs4                                      0.0.2\n",
      "build                                    1.0.3\n",
      "cachetools                               5.3.2\n",
      "certifi                                  2024.2.2\n",
      "charset-normalizer                       3.3.2\n",
      "chroma-hnswlib                           0.7.3\n",
      "chromadb                                 0.4.22\n",
      "click                                    8.1.7\n",
      "colorama                                 0.4.6\n",
      "coloredlogs                              15.0.1\n",
      "comm                                     0.2.1\n",
      "contourpy                                1.2.0\n",
      "cycler                                   0.12.1\n",
      "dataclasses-json                         0.6.4\n",
      "debugpy                                  1.8.1\n",
      "decorator                                5.1.1\n",
      "deep-translator                          1.11.4\n",
      "deepl                                    1.17.0\n",
      "Deprecated                               1.2.14\n",
      "dill                                     0.3.8\n",
      "dirtyjson                                1.0.8\n",
      "distro                                   1.9.0\n",
      "docx2txt                                 0.8\n",
      "entrypoints                              0.4\n",
      "exceptiongroup                           1.2.0\n",
      "executing                                2.0.1\n",
      "Faker                                    23.2.1\n",
      "fastapi                                  0.109.2\n",
      "favicon                                  0.7.0\n",
      "ffmpy                                    0.3.2\n",
      "filelock                                 3.13.1\n",
      "flatbuffers                              23.5.26\n",
      "fonttools                                4.49.0\n",
      "frozendict                               2.4.0\n",
      "frozenlist                               1.4.1\n",
      "fsspec                                   2024.2.0\n",
      "gitdb                                    4.0.11\n",
      "GitPython                                3.1.42\n",
      "google-auth                              2.28.0\n",
      "google-trans-new                         1.1.9\n",
      "googleapis-common-protos                 1.62.0\n",
      "gradio                                   4.19.2\n",
      "gradio_client                            0.10.1\n",
      "greenlet                                 3.0.3\n",
      "grpcio                                   1.60.1\n",
      "h11                                      0.14.0\n",
      "htbuilder                                0.6.2\n",
      "httpcore                                 1.0.3\n",
      "httptools                                0.6.1\n",
      "httpx                                    0.25.2\n",
      "huggingface-hub                          0.20.3\n",
      "humanfriendly                            10.0\n",
      "humanize                                 4.9.0\n",
      "idna                                     3.6\n",
      "importlib-metadata                       6.11.0\n",
      "importlib-resources                      6.1.1\n",
      "ipykernel                                6.29.2\n",
      "ipython                                  8.21.0\n",
      "ipywidgets                               8.1.2\n",
      "jedi                                     0.19.1\n",
      "Jinja2                                   3.1.3\n",
      "joblib                                   1.3.2\n",
      "jsonpatch                                1.33\n",
      "jsonpointer                              2.4\n",
      "jsonschema                               4.21.1\n",
      "jsonschema-specifications                2023.12.1\n",
      "jupyter_client                           8.6.0\n",
      "jupyter_core                             5.7.1\n",
      "jupyterlab_widgets                       3.0.10\n",
      "kiwisolver                               1.4.5\n",
      "kubernetes                               29.0.0\n",
      "langchain                                0.1.9\n",
      "langchain-community                      0.0.24\n",
      "langchain-core                           0.1.26\n",
      "langdetect                               1.0.9\n",
      "langsmith                                0.1.8\n",
      "llama-index                              0.10.10\n",
      "llama-index-agent-openai                 0.1.4\n",
      "llama-index-cli                          0.1.3\n",
      "llama-index-core                         0.10.10\n",
      "llama-index-embeddings-huggingface       0.1.4\n",
      "llama-index-embeddings-openai            0.1.5\n",
      "llama-index-indices-managed-llama-cloud  0.1.2\n",
      "llama-index-legacy                       0.9.48\n",
      "llama-index-llms-ollama                  0.1.2\n",
      "llama-index-llms-openai                  0.1.5\n",
      "llama-index-multi-modal-llms-openai      0.1.3\n",
      "llama-index-program-openai               0.1.3\n",
      "llama-index-question-gen-openai          0.1.2\n",
      "llama-index-readers-file                 0.1.5\n",
      "llama-index-readers-llama-parse          0.1.2\n",
      "llama-index-vector-stores-chroma         0.1.2\n",
      "llama-parse                              0.3.4\n",
      "llamaindex-py-client                     0.1.13\n",
      "lxml                                     5.1.0\n",
      "Mako                                     1.3.2\n",
      "Markdown                                 3.5.2\n",
      "markdown-it-py                           3.0.0\n",
      "markdownlit                              0.0.7\n",
      "MarkupSafe                               2.1.5\n",
      "marshmallow                              3.20.2\n",
      "matplotlib                               3.8.3\n",
      "matplotlib-inline                        0.1.6\n",
      "mdurl                                    0.1.2\n",
      "merkle-json                              1.0.0\n",
      "millify                                  0.1.1\n",
      "mmh3                                     4.1.0\n",
      "monotonic                                1.6\n",
      "more-itertools                           10.2.0\n",
      "mpmath                                   1.3.0\n",
      "multidict                                6.0.5\n",
      "munch                                    4.0.0\n",
      "mypy-extensions                          1.0.0\n",
      "nest-asyncio                             1.6.0\n",
      "networkx                                 3.2.1\n",
      "nltk                                     3.8.1\n",
      "numpy                                    1.26.4\n",
      "oauthlib                                 3.2.2\n",
      "ollama                                   0.1.7\n",
      "onnxruntime                              1.17.0\n",
      "openai                                   1.12.0\n",
      "opentelemetry-api                        1.22.0\n",
      "opentelemetry-exporter-otlp-proto-common 1.22.0\n",
      "opentelemetry-exporter-otlp-proto-grpc   1.22.0\n",
      "opentelemetry-instrumentation            0.43b0\n",
      "opentelemetry-instrumentation-asgi       0.43b0\n",
      "opentelemetry-instrumentation-fastapi    0.43b0\n",
      "opentelemetry-proto                      1.22.0\n",
      "opentelemetry-sdk                        1.22.0\n",
      "opentelemetry-semantic-conventions       0.43b0\n",
      "opentelemetry-util-http                  0.43b0\n",
      "orjson                                   3.9.15\n",
      "overrides                                7.7.0\n",
      "packaging                                23.2\n",
      "pandas                                   2.2.0\n",
      "parso                                    0.8.3\n",
      "pillow                                   10.2.0\n",
      "pip                                      24.0\n",
      "platformdirs                             4.2.0\n",
      "posthog                                  3.4.2\n",
      "prometheus_client                        0.20.0\n",
      "prompt-toolkit                           3.0.43\n",
      "protobuf                                 4.25.3\n",
      "psutil                                   5.9.8\n",
      "pulsar-client                            3.4.0\n",
      "pure-eval                                0.2.2\n",
      "pyarrow                                  15.0.0\n",
      "pyasn1                                   0.5.1\n",
      "pyasn1-modules                           0.3.0\n",
      "pydantic                                 2.6.1\n",
      "pydantic_core                            2.16.2\n",
      "pydeck                                   0.8.1b0\n",
      "pydub                                    0.25.1\n",
      "Pygments                                 2.17.2\n",
      "pygpt4all                                1.1.0\n",
      "pygptj                                   2.0.3\n",
      "pyllamacpp                               2.4.2\n",
      "pymdown-extensions                       10.7\n",
      "PyMuPDF                                  1.23.25\n",
      "PyMuPDFb                                 1.23.22\n",
      "pyparsing                                3.1.1\n",
      "pypdf                                    4.0.2\n",
      "PyPika                                   0.48.9\n",
      "pyproject_hooks                          1.0.0\n",
      "pyreadline3                              3.4.1\n",
      "python-dateutil                          2.8.2\n",
      "python-decouple                          3.8\n",
      "python-dotenv                            1.0.1\n",
      "python-multipart                         0.0.9\n",
      "pytz                                     2024.1\n",
      "pywin32                                  306\n",
      "PyYAML                                   6.0.1\n",
      "pyzmq                                    25.1.2\n",
      "referencing                              0.33.0\n",
      "regex                                    2023.12.25\n",
      "requests                                 2.31.0\n",
      "requests-oauthlib                        1.3.1\n",
      "rich                                     13.7.0\n",
      "rpds-py                                  0.18.0\n",
      "rsa                                      4.9\n",
      "ruff                                     0.2.2\n",
      "safetensors                              0.4.2\n",
      "scikit-learn                             1.4.1.post1\n",
      "scipy                                    1.12.0\n",
      "semantic-version                         2.10.0\n",
      "sentence-transformers                    2.4.0\n",
      "setuptools                               65.5.0\n",
      "shellingham                              1.5.4\n",
      "six                                      1.16.0\n",
      "smmap                                    5.0.1\n",
      "sniffio                                  1.3.0\n",
      "soupsieve                                2.5\n",
      "SQLAlchemy                               2.0.27\n",
      "st-annotated-text                        4.0.1\n",
      "stack-data                               0.6.3\n",
      "starlette                                0.36.3\n",
      "streamlit                                1.31.1\n",
      "streamlit-aggrid                         0.3.4.post3\n",
      "streamlit-camera-input-live              0.2.0\n",
      "streamlit-card                           1.0.0\n",
      "streamlit-embedcode                      0.1.2\n",
      "streamlit-extras                         0.4.0\n",
      "streamlit-faker                          0.0.3\n",
      "streamlit-image-coordinates              0.1.6\n",
      "streamlit-keyup                          0.2.3\n",
      "streamlit-toggle-switch                  1.0.2\n",
      "streamlit-vertical-slider                2.5.5\n",
      "sympy                                    1.12\n",
      "tenacity                                 8.2.3\n",
      "threadpoolctl                            3.3.0\n",
      "tiktoken                                 0.6.0\n",
      "tokenizers                               0.15.2\n",
      "toml                                     0.10.2\n",
      "tomli                                    2.0.1\n",
      "tomlkit                                  0.12.0\n",
      "toolz                                    0.12.1\n",
      "torch                                    2.2.1\n",
      "tornado                                  6.4\n",
      "tqdm                                     4.66.2\n",
      "traitlets                                5.14.1\n",
      "transformers                             4.38.1\n",
      "trulens-eval                             0.24.1\n",
      "typer                                    0.9.0\n",
      "typing_extensions                        4.9.0\n",
      "typing-inspect                           0.9.0\n",
      "tzdata                                   2024.1\n",
      "tzlocal                                  5.2\n",
      "urllib3                                  2.2.1\n",
      "uvicorn                                  0.27.1\n",
      "validators                               0.22.0\n",
      "watchdog                                 4.0.0\n",
      "watchfiles                               0.21.0\n",
      "wcwidth                                  0.2.13\n",
      "websocket-client                         1.7.0\n",
      "websockets                               11.0.3\n",
      "widgetsnbextension                       4.0.10\n",
      "wrapt                                    1.16.0\n",
      "yarl                                     1.9.4\n",
      "zipp                                     3.17.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip list sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "aa9c3b90",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[105], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msources\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtext\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "sources[2].text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
